{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75f43a03-d83d-4551-ac9a-4ac4d0764b32",
    "_uuid": "668599ac03c8b70093377c7250cd34e93ba6cffe"
   },
   "source": [
    "## More Feature extraction and some other classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import useful sklearn kits and other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "0456a8ef-0aca-4b40-8199-0e4fdec81671",
    "_uuid": "025540f501355cfb33e6bc256ad3c0980793d0fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15663,)\n",
      "(3916,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#---------------\n",
    "use_hashing = False\n",
    "select_chi2 = False\n",
    "n_features = 2 ** 16\n",
    "print_top10 = False\n",
    "print_report = True\n",
    "print_cm = True\n",
    "\n",
    "###########################################\n",
    "# read in data\n",
    "trainall_df = pd.read_csv(\"../input/train.csv\")\n",
    "\n",
    "# split a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainall_df.text, trainall_df.author, test_size = 0.2, random_state = 1)\n",
    "# y_train = LabelBinarizer().fit_transform(y_train)\n",
    "# y_test = LabelBinarizer().fit_transform(y_test)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing and extract features(use Vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 0.801692s\n",
      "n_samples: 15663, n_features: 22759\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.227835s\n",
      "n_samples: 3916, n_features: 22759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract features\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', alternate_sign=False,\n",
    "                                   n_features=n_features)\n",
    "    X_train = vectorizer.transform(X_train)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "duration = time() - t0\n",
    "print(\"done in %fs\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(X_test)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "if use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# use chi2 or not\n",
    "if select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "          opts.select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names:\n",
    "        # keep selected feature names\n",
    "        feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "target_names = ['EAP','HPL','MWS']\n",
    "    \n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The benchmark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='sag',\n",
      "        tol=0.01)\n",
      "train time: 0.884s\n",
      "test time:  0.002s\n",
      "accuracy:   0.805\n",
      "dimensionality: 22759\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.77      0.85      0.81      1530\n",
      "        HPL       0.84      0.76      0.80      1144\n",
      "        MWS       0.83      0.79      0.81      1242\n",
      "\n",
      "avg / total       0.81      0.80      0.80      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1304  104  122]\n",
      " [ 193  865   86]\n",
      " [ 200   59  983]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=500, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=0.01, verbose=0, warm_start=False)\n",
      "train time: 0.056s\n",
      "test time:  0.002s\n",
      "accuracy:   0.767\n",
      "dimensionality: 22759\n",
      "density: 0.572697\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.74      0.81      0.78      1530\n",
      "        HPL       0.80      0.71      0.75      1144\n",
      "        MWS       0.77      0.76      0.77      1242\n",
      "\n",
      "avg / total       0.77      0.77      0.77      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1243  121  166]\n",
      " [ 216  813  115]\n",
      " [ 214   79  949]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=500, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=0.01,\n",
      "              verbose=0, warm_start=False)\n",
      "train time: 0.113s\n",
      "test time:  0.002s\n",
      "accuracy:   0.787\n",
      "dimensionality: 22759\n",
      "density: 0.875053\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.77      0.81      0.79      1530\n",
      "        HPL       0.82      0.76      0.79      1144\n",
      "        MWS       0.78      0.79      0.79      1242\n",
      "\n",
      "avg / total       0.79      0.79      0.79      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1234  127  169]\n",
      " [ 172  867  105]\n",
      " [ 199   62  981]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.030s\n",
      "test time:  2.177s\n",
      "accuracy:   0.352\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.40      0.43      0.42      1530\n",
      "        HPL       0.71      0.00      0.01      1144\n",
      "        MWS       0.32      0.57      0.41      1242\n",
      "\n",
      "avg / total       0.47      0.35      0.29      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[664   1 865]\n",
      " [461   5 678]\n",
      " [530   1 711]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 70.373s\n",
      "test time:  1.243s\n",
      "accuracy:   0.703\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.66      0.79      0.72      1530\n",
      "        HPL       0.74      0.63      0.68      1144\n",
      "        MWS       0.74      0.67      0.70      1242\n",
      "\n",
      "avg / total       0.71      0.70      0.70      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1206  138  186]\n",
      " [ 314  717  113]\n",
      " [ 299  113  830]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.587s\n",
      "test time:  0.002s\n",
      "accuracy:   0.808\n",
      "dimensionality: 22759\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.78      0.84      0.81      1530\n",
      "        HPL       0.83      0.78      0.80      1144\n",
      "        MWS       0.82      0.80      0.81      1242\n",
      "\n",
      "avg / total       0.81      0.81      0.81      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1288  114  128]\n",
      " [ 173  887   84]\n",
      " [ 189   62  991]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "train time: 7.221s\n",
      "test time:  0.002s\n",
      "accuracy:   0.807\n",
      "dimensionality: 22759\n",
      "density: 0.854695\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.77      0.85      0.81      1530\n",
      "        HPL       0.83      0.77      0.80      1144\n",
      "        MWS       0.84      0.79      0.81      1242\n",
      "\n",
      "avg / total       0.81      0.81      0.81      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1297  111  122]\n",
      " [ 190  884   70]\n",
      " [ 197   67  978]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.992s\n",
      "test time:  0.002s\n",
      "accuracy:   0.778\n",
      "dimensionality: 22759\n",
      "density: 0.169427\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.73      0.84      0.78      1530\n",
      "        HPL       0.82      0.72      0.77      1144\n",
      "        MWS       0.81      0.76      0.78      1242\n",
      "\n",
      "avg / total       0.78      0.78      0.78      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1282  105  143]\n",
      " [ 237  823   84]\n",
      " [ 229   73  940]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "train time: 10.492s\n",
      "test time:  0.002s\n",
      "accuracy:   0.734\n",
      "dimensionality: 22759\n",
      "density: 0.056930\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.67      0.84      0.74      1530\n",
      "        HPL       0.79      0.64      0.71      1144\n",
      "        MWS       0.80      0.69      0.74      1242\n",
      "\n",
      "avg / total       0.75      0.73      0.73      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1291  107  132]\n",
      " [ 341  728   75]\n",
      " [ 305   83  854]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 11.182s\n",
      "test time:  0.002s\n",
      "accuracy:   0.796\n",
      "dimensionality: 22759\n",
      "density: 0.536960\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.75      0.86      0.80      1530\n",
      "        HPL       0.83      0.75      0.79      1144\n",
      "        MWS       0.83      0.76      0.80      1242\n",
      "\n",
      "avg / total       0.80      0.80      0.80      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1310  104  116]\n",
      " [ 208  862   74]\n",
      " [ 218   77  947]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.046s\n",
      "test time:  0.003s\n",
      "accuracy:   0.738\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.72      0.77      0.74      1530\n",
      "        HPL       0.71      0.74      0.73      1144\n",
      "        MWS       0.80      0.70      0.75      1242\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1173  207  150]\n",
      " [ 225  846   73]\n",
      " [ 236  136  870]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.084s\n",
      "test time:  0.002s\n",
      "accuracy:   0.813\n",
      "dimensionality: 22759\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.80      0.81      0.81      1530\n",
      "        HPL       0.83      0.80      0.82      1144\n",
      "        MWS       0.81      0.82      0.82      1242\n",
      "\n",
      "avg / total       0.81      0.81      0.81      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1241  121  168]\n",
      " [ 154  920   70]\n",
      " [ 157   61 1024]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.083s\n",
      "test time:  0.008s\n",
      "accuracy:   0.818\n",
      "dimensionality: 22759\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.79      0.84      0.81      1530\n",
      "        HPL       0.86      0.78      0.82      1144\n",
      "        MWS       0.82      0.82      0.82      1242\n",
      "\n",
      "avg / total       0.82      0.82      0.82      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1285   91  154]\n",
      " [ 174  896   74]\n",
      " [ 168   52 1022]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 1.162s\n",
      "test time:  0.007s\n",
      "accuracy:   0.791\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.76      0.83      0.79      1530\n",
      "        HPL       0.82      0.75      0.78      1144\n",
      "        MWS       0.81      0.77      0.79      1242\n",
      "\n",
      "avg / total       0.79      0.79      0.79      3916\n",
      "\n",
      "confusion matrix:\n",
      "[[1276  117  137]\n",
      " [ 196  859   89]\n",
      " [ 209   72  961]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMYxLkiRJPTGMS5IkST0xjEuSJEk9+f/TUMZjXYuM0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdea61ca0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "       # (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(tol=1e-2,max_iter=500), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(tol=1e-2,max_iter=500), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=500,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=500,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Naive Bayes gets log_loss = 0.487134977592\n",
    "# Simple Perceptron gets log_loss = 7.14412892745\n",
    "# Simple Logistic Regression gets log_loss = 6.315057171537\n",
    "# print('log_loss = ', score)\n",
    "\n",
    "# print out to a output file\n",
    "# predictions = pd.DataFrame(\n",
    "#    unigrams_pipeline.predict_proba(test_df.text),\n",
    "#    columns=unigrams_pipeline.classes_\n",
    "#                           )\n",
    "#predictions['id'] = test_df['id']\n",
    "#predictions.to_csv(\"submission.csv\", index=False, columns=['id','EAP','HPL','MWS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
